{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Task 3: DDI Baseline\n",
    "### Authors: David Curto & David Hilazo\n",
    "\n",
    "The aim of this lab is to implement a handcrafted RULE-based classifier which is able to detect interactions between pairs of drugs and their type. This task is inspired in the Semeval-2013 Task 9 DDI-Extraction.The goal of this task is to obtain a **F1 Score of 0.15 on the Devel set** with just using rules(no ML method)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief description of used linguistic information\n",
    "\n",
    "In order to detect the interaction between drugs we have used as many linguistic information as we could. At the beginning we only focus on **word level(tokens)** but it obviously was not good enough, so we started using more information like **Part of Speech(PoS)**. With PoS tags we were able to detect how each token was used in that sentence(verb, noun, adjective...) and retrieve more insights about the interaction and discard some forms that may never appear within an interaction. Finally, we include all the information that the Stanford CoreNLP Dependency parser gives, which is all the information mentioned previously but many more. With the parser information we have been able to detect the **relations** and **dependencies** between tokens, which nodes are shared, how they interact and many more features that have been extremely useful for tackling this drug interaction extraction problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief description of used/discarded rules\n",
    "\n",
    "In order to detect the interaction between drugs, we started with a really simple approach that was to look at **common words that appear between the drugs** for each interaction type.\n",
    "\n",
    "We have included all this rules in the function ``rules_without_dependency``. To search which where the common words for each type we just grouped by interaction type and count the frequency of each word between the pair of drugs in the training dataset, but also considering their frequency in the no interaction case. With this approach we extracted which are the most commond words for each type and built a specific rule for every type.\n",
    "\n",
    "The next rule we tried was based on the **distance(in terms of words) between the pair of drugs**. The reason behind this rule is that we supposed that drugs which are far away are less likely to interact. After visualising the results for true and false ddis we observed that our supposition was true, however the distance for detecting if true drugs interact or not was too high that is was not really useful at all because there were really few instances classified from this rule. For this reason we decided it to discard it.\n",
    "\n",
    "At this point, with only the first rules, we were really close to achieve the F1 score of 0.15 on Devel dataset. To improve the performance we started exploring rules using more complex information from the dependency tree. \n",
    "\n",
    "Instead of looking at common words between the words, we decided to go further and extract which were the **most common root lemmas** for each interaction type. This rules are based on extracting the lemma of the root from the dependency tree and check if is one of the most common root lemas for each type such as advise, recommend, suggest for *advise* type or enhance, inhibit, block, produce for *effect* type. The reason behind this rule is that sometimes the interaction verb is not between this words but before or after them.\n",
    "\n",
    "Continuing with the dependency tree we extracted the **common ancestor for the pair of drugs** and analyze it for each type. After analysing the results we came up with one rule for the *int* type that was to look if the common ancestor was \"interact\" or \"interaction\" and its postag was a noun or verb type (NN,NNS,VB,VBP).\n",
    "\n",
    "At this point, we already had achieved the minimum score but, after analyzing the false positives DDIs we added one last rule, that was to **compare if the drug names were the same**. In that case , there couldn't be an interaction. This was a quite simple rule but avoided several misclassification.\n",
    "\n",
    "Other discarded rules that we tried was analyzing the **heads of each drug**, but this was quite problematic for the compounnd drug names or those drugs that contain text between their names and there were not useful patterns. Another rule that we tried was to focus only on the **common ancestor verbs**, but this was not good enough because it failed to detect nouns formed from verbs such as interaction.\n",
    "\n",
    "Since we already achieved the minimum score in this lab, we decided not to add more rules even though we have explored some others which will be used in the ML model such as looking at the dependencies of the shortest path.\n",
    "\n",
    "As an overview of the rules tested and which ones are used and which ones are discarded the following table is used for this purpose\n",
    "\n",
    "|           Rules  Used       |     Rules     Discarded     |\n",
    "|:---------------------------:|:---------------------------:|\n",
    "|  Common words between drugs |    Distance between drugs   |\n",
    "|      Common root lemmas     |      Head of each drug      |\n",
    "| Common ancestor (PoS,Lemma) | Common ancestor (verb only) |\n",
    "|          Drug names         |                             |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code with its corresponding comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Libraries and modules import**\n",
    "\n",
    "To implement this DDI detector, we have used just some useful libraries/modules which are the ElementTree XML for parsing the input files which are in XML format and the Stanford CoreNLP Dependency parser that is used for tokenizing the sentences, PoS tagging and parsing them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Offset addition**\n",
    "\n",
    "This function receives the parse of the Stanford CoreNLP Dependency Parser and the text parsed and iterates through the nodes in order to add two more attributes which are:the start and the end position of the token within the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_offset_to_tree(parse, text, offset=0):\n",
    "    for key in range(len(parse.nodes)):\n",
    "        value = parse.nodes[key]\n",
    "        # Check that word exists and its not punctuation\n",
    "        if value['word'] and value['rel'] != 'punct':\n",
    "            start = text.find(value['word'], offset)\n",
    "            parse.nodes[key]['start_off'] = start\n",
    "            if len(value['word']) > 1:\n",
    "                parse.nodes[key]['end_off'] = len(value['word']) - 1 + start\n",
    "            else:\n",
    "                parse.nodes[key]['end_off'] = len(value['word']) + start\n",
    "            offset = start + len(value['word'])\n",
    "\n",
    "        elif value['rel'] == 'punct':\n",
    "            parse.nodes[key]['start_off'] = offset\n",
    "            parse.nodes[key]['end_off'] = offset + 1\n",
    "            offset += 1\n",
    "\n",
    "    return parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyze**\n",
    "\n",
    "This function establishes the connection with the CoreNLPDependencyParser server which is running in the localhost and sends to the server the sentence that wants to parse. This function will return the sentence parsed, tokenized and PoS-tagged with the start and end offset included.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(stext):\n",
    "    parser = CoreNLPDependencyParser(url=\"http://localhost:9000\")\n",
    "\n",
    "    if '\\r\\n' in stext:\n",
    "        stext = stext.replace('\\r\\n', '  ')\n",
    "    iterator = parser.raw_parse(stext)\n",
    "    parse = next(iterator)\n",
    "    #Add the offsets to the tree\n",
    "    parse = add_offset_to_tree(parse, stext)\n",
    "\n",
    "    return parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependengy graph features extraction\n",
    "\n",
    "**Find common ancestor**\n",
    "\n",
    "This function finds the common ancestor of the two entities analyzed(pairs of drugs) and if it finds a common parent node between this drug it returns the lemma of the common parent and its postag. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_common_ancestor(analysis, first_index, second_index):\n",
    "    visited_first = [first_index]\n",
    "    visited_second = [second_index]\n",
    "\n",
    "    while not (analysis.root['address'] in visited_first and analysis.root['address'] in visited_second):\n",
    "        head = analysis.nodes[first_index]['head']\n",
    "        if head is not None:\n",
    "            visited_first.append(head)\n",
    "            first_index = head\n",
    "        head = analysis.nodes[second_index]['head']\n",
    "        if head is not None:\n",
    "            visited_second.append(head)\n",
    "            second_index = head\n",
    "        #Find the intersection between the drugs\n",
    "        intersection = list(set(visited_first) & set(visited_second))\n",
    "        if intersection:\n",
    "                return analysis.nodes[intersection[0]][\"lemma\"], analysis.nodes[intersection[0]][\"tag\"]\n",
    "\n",
    "    return 'None', 'None'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract head drugs info**\n",
    "\n",
    "This function returns the lemma and PoS tag of the head node of each drug. The head node will be set to the first head node which is not in any of the nodes of the Drug 1 and Drug 2. This restriction has been set due to composite drug names that were splitted into different nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_head_drugs_info(analysis, nodes_drug1, nodes_drug2):\n",
    "    drug1_node = nodes_drug1[0]\n",
    "    drug2_node = nodes_drug2[0]\n",
    "    counter_d1 = counter_d2 = 0\n",
    "    head1_found = head2_found = False\n",
    "    \n",
    "    while not head1_found or not head2_found:\n",
    "        # Get the Lemma and Tag of drug's head\n",
    "        head_drug1 = analysis.nodes[drug1_node[\"head\"]]\n",
    "        head_drug2 = analysis.nodes[drug2_node[\"head\"]]\n",
    "        lemma_pos_d1 = (head_drug1[\"lemma\"], head_drug1[\"tag\"])\n",
    "        lemma_pos_d2 = (head_drug2[\"lemma\"], head_drug2[\"tag\"])\n",
    "        # Check that the head is not part of the drug(composite names)\n",
    "        if head_drug1 in nodes_drug1:\n",
    "            counter_d1 = counter_d1 + 1\n",
    "            drug1_node = nodes_drug1[counter_d1]\n",
    "        else:\n",
    "            head1_found = True\n",
    "        if head_drug2 in nodes_drug2:\n",
    "            counter_d2 = counter_d2 + 1\n",
    "            drug2_node = nodes_drug2[counter_d2]\n",
    "        else:\n",
    "            head2_found = True\n",
    "\n",
    "    return lemma_pos_d1, lemma_pos_d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract in between text**: This function extracts the text that it is between the drug1 and drug 2(without including the drugs' names in the extracted sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_inbetween_text(analysis, entities, id_e1, id_e2):\n",
    "    index_drug1 = index_drug2 = 0\n",
    "    sentece_analysis = [None] * (len(analysis.nodes) - 1)\n",
    "    for i_node in range(1, len(analysis.nodes)):\n",
    "        current_node = analysis.nodes[i_node]\n",
    "        address = current_node[\"address\"]\n",
    "        word = current_node[\"word\"]\n",
    "        start = current_node[\"start_off\"]\n",
    "        end = current_node[\"end_off\"]\n",
    "        end_drug1 = entities[id_e1][0][1] if len(entities[id_e1] == 1) else entities[id_e1][len(entities[id_e1]) - 1][1]\n",
    "        if end == end_drug1:\n",
    "            index_drug1 = i_node - 1\n",
    "        if start == entities[id_e2][0][0]:\n",
    "            index_drug2 = i_node - 1\n",
    "        sentece_analysis[address - 1] = word\n",
    "    inbetween_text = ' '.join(sentece_analysis[index_drug1:index_drug2])\n",
    "    return inbetween_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract distance between drugs** \n",
    "\n",
    "This function returns the distance that exists between the end of the first drug and the start of the second drug. The distance is computed in terms of tokens(words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_distance_between_drugs(nodes_drug1, nodes_drug2):\n",
    "    max_d1 = max([i[\"address\"] for i in nodes_drug1])\n",
    "    min_d1 = min([i[\"address\"] for i in nodes_drug2])\n",
    "    distance = abs(min_d1 - max_d1)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract drug names:** \n",
    "This function extracts the names of each drug and, in case that it is splitted in multiple nodes, those are joined to form the drug name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_drug_name(entities,id, nodes_drug):\n",
    "    drug = []\n",
    "    for node in nodes_drug:\n",
    "        if len(entities[id]) < 2:\n",
    "            drug.append(node[\"word\"])\n",
    "        else:\n",
    "            if not (node[\"start_off\"] > entities[id][0][1] and node[\"end_off\"] < entities[id][1][0]):\n",
    "                drug.append(node[\"word\"])\n",
    "    return \" \".join(drug)\n",
    "\n",
    "def extract_drug_names(entities, id_e1, id_e2, nodes_drug1, nodes_drug2):\n",
    "    drug1 = extract_drug_name(entities, id_e1, nodes_drug1)\n",
    "    drug2 = extract_drug_name(entities, id_e2, nodes_drug2)\n",
    "    return drug1, drug2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract drug nodes:** This function returns the list of the nodes that contain a part or the whole name of each one of the drugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_drug_nodes(analysis, e1_off, e2_off):\n",
    "    nodes_drug1 = []\n",
    "    nodes_drug2 = []\n",
    "    #Initialize stard and end of each drug\n",
    "    start_drug1 = e1_off[0][0]\n",
    "    start_drug2 = e2_off[0][0]\n",
    "    end_drug1 = e1_off[0][1] if len(e1_off) < 2 else e1_off[len(e1_off) - 1][1]\n",
    "    end_drug2 = e2_off[0][1] if len(e2_off) < 2 else e2_off[len(e2_off) - 1][1]\n",
    "\n",
    "    for i_node in range(1, len(analysis.nodes)):\n",
    "        current_node = analysis.nodes[i_node]\n",
    "        start = current_node[\"start_off\"]\n",
    "        end = current_node[\"end_off\"]\n",
    "        #Append the nodes that are between the start and end\n",
    "        if start == start_drug1 or (start < start_drug1 <= end):\n",
    "            nodes_drug1.append(current_node)\n",
    "        if start == start_drug2 or (start < start_drug2 <= end):\n",
    "            nodes_drug2.append(current_node)\n",
    "        if start != start_drug1:\n",
    "            if end == end_drug1 or (start < end_drug1 <= end) or(start_drug1 < end < end_drug1):\n",
    "                nodes_drug1.append(current_node)\n",
    "        if start != start_drug2:\n",
    "            if end == end_drug2 or (start < end_drug2 <= end) or(start_drug2 < end < end_drug2):\n",
    "                nodes_drug2.append(current_node)\n",
    "\n",
    "    return nodes_drug1, nodes_drug2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rules without dependency**\n",
    "\n",
    "This are the rules that we extract based on analyzing which were the most common words that appear between the two drugs for each type of interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rules_without_dependency(sentence):\n",
    "    is_ddi = 0\n",
    "    ddi_type = \"null\"\n",
    "    effect_list = ['administer', 'potentiate', 'prevent', 'effect', 'cause']\n",
    "    #Look for most common words for each DDI type\n",
    "    if \"effect\" in sentence:\n",
    "        is_ddi = 1\n",
    "        ddi_type = \"effect\"\n",
    "    if \"should\" in sentence:\n",
    "        is_ddi = 1\n",
    "        ddi_type = \"advise\"\n",
    "    if \"increase\" in sentence or \"decrease\" in sentence or \"reduce\" in sentence:\n",
    "        is_ddi = 1\n",
    "        ddi_type = \"mechanism\"\n",
    "\n",
    "    return is_ddi, ddi_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check interaction**\n",
    "\n",
    "This is the function that is in charge of deciding whether there is an interaction between two drugs and if that is the case which type of interaction is. Several rules have been tested using more complex information and others with just looking at the word level, however in this function there are just the ones that achieved a decent F1 score on all datasets(Train, Devel and Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_interaction(analysis, entities, id_e1, id_e2):\n",
    "    #Extract the text between the pair of drugs\n",
    "    inbetween_text = extract_inbetween_text(analysis, entities, id_e1, id_e2)\n",
    "    \n",
    "    #Extract if is ddi and the type(less restrictive rule)\n",
    "    (is_ddi, ddi_type) = rules_without_dependency(inbetween_text)\n",
    "\n",
    "    e1_off = entities[id_e1]\n",
    "    e2_off = entities[id_e2]\n",
    "    \n",
    "    #Extract more complex information using the dependency tree relations\n",
    "    nodes_drug1, nodes_drug2 = extract_drug_nodes(analysis, e1_off, e2_off)\n",
    "    drug1, drug2 = extract_drug_names(entities, id_e1, id_e2, nodes_drug1, nodes_drug2)\n",
    "    head_drug1, head_drug2 = extract_head_drugs_info(analysis, nodes_drug1, nodes_drug2)\n",
    "    distance = extract_distance_between_drugs(nodes_drug1, nodes_drug2)\n",
    "    common_ancestor_info = find_common_ancestor(analysis, nodes_drug1[0][\"address\"], nodes_drug2[0][\"address\"])\n",
    "    \n",
    "    #If the drugs are the same they can't have an interaction\n",
    "    if drug1 == drug2:\n",
    "        return 0, 'null'\n",
    "    \n",
    "    # Check the common ancestor and its tag (special case for Int type)\n",
    "    if common_ancestor_info[0] in ['interact', 'interaction']:\n",
    "        if common_ancestor_info[1] in ['NN', 'VB', 'NNS', 'VBP']:\n",
    "            return 1, 'int'\n",
    "        \n",
    "    # Check if root contains any of the most common words for advise interaction type\n",
    "    if analysis.root['lemma'] in ['advise', 'recommend', 'contraindicate', 'suggest']:\n",
    "        return 1, 'advise'\n",
    "    \n",
    "    # Check if root contains any of the most common words for effect interaction type\n",
    "    if analysis.root['lemma'] in ['enhance', 'inhibit', 'block', 'produce']:\n",
    "        return 1, 'effect'\n",
    "    \n",
    "    # If none of the previous rules is fired, then the basic rules output is used\n",
    "    if is_ddi:\n",
    "        return is_ddi, ddi_type\n",
    "\n",
    "    return 0, 'null'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw output of the Semeval evaluator on DEVEL dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SCORES FOR THE GROUP: out RUN=1\n",
    "Gold Dataset: /\n",
    "\n",
    "Partial Evaluation: only detection of DDI (regadless to the type)\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "226\t424\t258\t484\t0,3477\t0,4669\t0,3986\n",
    "\n",
    "\n",
    "Detection and Classification of DDI\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "162\t488\t322\t484\t0,2492\t0,3347\t0,2857\n",
    "\n",
    "\n",
    "________________________________________________________________________\n",
    "\n",
    "SCORES FOR DDI TYPE\n",
    "Scores for ddi with type mechanism\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "80\t275\t121\t201\t0,2254\t0,398\t0,2878\n",
    "\n",
    "\n",
    "Scores for ddi with type effect\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "55\t142\t107\t162\t0,2792\t0,3395\t0,3064\n",
    "\n",
    "\n",
    "Scores for ddi with type advise\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "25\t39\t94\t119\t0,3906\t0,2101\t0,2732\n",
    "\n",
    "\n",
    "Scores for ddi with type int\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "2\t32\t0\t2\t0,0588\t1\t0,1111\n",
    "\n",
    "\n",
    "MACRO-AVERAGE MEASURES:\n",
    "\tP\tR\tF1\n",
    "\t0,2385\t0,4869\t0,3202\n",
    "________________________________________________________________________\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw output of the Semeval evaluator on TEST dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SCORES FOR THE GROUP: out RUN=1\n",
    "Gold Dataset: /\n",
    "\n",
    "Partial Evaluation: only detection of DDI (regadless to the type)\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "430\t915\t549\t979\t0,3197\t0,4392\t0,3701\n",
    "\n",
    "\n",
    "Detection and Classification of DDI\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "305\t1040\t674\t979\t0,2268\t0,3115\t0,2625\n",
    "\n",
    "\n",
    "________________________________________________________________________\n",
    "\n",
    "SCORES FOR DDI TYPE\n",
    "Scores for ddi with type mechanism\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "99\t406\t203\t302\t0,196\t0,3278\t0,2454\n",
    "\n",
    "\n",
    "Scores for ddi with type effect\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "68\t336\t292\t360\t0,1683\t0,1889\t0,178\n",
    "\n",
    "\n",
    "Scores for ddi with type advise\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "87\t210\t134\t221\t0,2929\t0,3937\t0,3359\n",
    "\n",
    "\n",
    "Scores for ddi with type int\n",
    "tp\tfp\tfn\ttotal\tprec\trecall\tF1\n",
    "51\t88\t45\t96\t0,3669\t0,5312\t0,434\n",
    "\n",
    "\n",
    "MACRO-AVERAGE MEASURES:\n",
    "\tP\tR\tF1\n",
    "\t0,256\t0,3604\t0,2994\n",
    "________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen in the evaluator output we have achieved the goal of this task which was to obtain a F1 score of 0.15 in Devel dataset. In fact, we have doubled the minimum value achieving a F1 score of 0.32.\n",
    "\n",
    "With the development of this task we have seen the importance of the dependecy tree to properly extract relations between words and without using this information we are sure that this task would have been much harder. The use of the dependency tree allowed us to extract the connection between tokens of the sentences even with unordered sentences or with passive forms. The most difficult type to detect was the int type due to the distribution of the types, being int the less representative class. \n",
    "\n",
    "During the development of this tasks we tested several rules, starting with quite simple ones which just look at the token (word) level without considering relations. However the great improvement came when we started considering the relations and finding which tokens(nodes) had in common.\n",
    "\n",
    "The metrics obtained in each one of the datasets is quite similar (0.33 on training, 0.32 on Devel and 0,299 on Test ) which implies that the rules extracted are quite generic and cover pretty well the patterns of each interaction type.\n",
    "\n",
    "During the process of rule selection we tested several values for each rule but our criteria was to left only the generic rules that performed well on all the splits of the data. To extract the knowledge of the most common values we have used automatic functions to describe the distribution of those values for each type and in some cases we have helped with visualizations charts to see at a glance if there were clear patterns (like in the distance between drugs). \n",
    "\n",
    "To conclude we would like to emphasize that we achieved decent results with very few rules and even though more rules could be applied we decided just to keep as few as possible while preserving a good performance. However, if further improvements should be made, we could start including more complex patterns like the ones used for Task 4. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bitc783764bfe924bbb9c6e0031c045fda6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
